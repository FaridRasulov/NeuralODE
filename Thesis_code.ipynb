{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2/kvw373rQzo3w1mkRjXC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaridRasulov/NeuralODE/blob/master/Thesis_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpPAPNBA2Y9W",
        "outputId": "87bba73c-92fa-4a66-b310-4c6e73dbd341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install torchdiffeq\n",
        "!pip install pytorch_utils\n",
        "!pip install tqdm\n",
        "!pip install adversarial-robustness-toolbox\n",
        "!pip install kornia"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchdiffeq\n",
            "  Downloading https://files.pythonhosted.org/packages/67/af/377e42c20058f4891dedc1827c1a6b7b16772a452d18097d05c1db06b338/torchdiffeq-0.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from torchdiffeq) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->torchdiffeq) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->torchdiffeq) (0.16.0)\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.1.1\n",
            "Collecting pytorch_utils\n",
            "  Downloading https://files.pythonhosted.org/packages/76/09/c4484bbf64cac23873589e7b5563d0ecb6457105098e34d7ef69950c06e3/pytorch_utils-0.5.5.tar.gz\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from pytorch_utils) (5.5.0)\n",
            "Collecting sacred\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/7f/c5679977f1eceac432c59cc92bd1ddb7272c282c3db8eb846d0e1c03b6a0/sacred-0.8.1.tar.gz (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_utils) (4.41.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from pytorch_utils) (3.11.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->pytorch_utils) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->pytorch_utils) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->pytorch_utils) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->pytorch_utils) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->pytorch_utils) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->pytorch_utils) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->pytorch_utils) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->pytorch_utils) (50.3.0)\n",
            "Requirement already satisfied: docopt<1.0,>=0.3 in /usr/local/lib/python3.6/dist-packages (from sacred->pytorch_utils) (0.6.2)\n",
            "Collecting jsonpickle<2.0,>=1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n",
            "Collecting munch<3.0,>=2.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wrapt<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from sacred->pytorch_utils) (1.12.1)\n",
            "Collecting py-cpuinfo>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/f5/8e6e85ce2e9f6e05040cf0d4e26f43a4718bcc4bce988b433276d4b1a5c1/py-cpuinfo-7.0.0.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 6.7MB/s \n",
            "\u001b[?25hCollecting colorama>=0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.6/dist-packages (from sacred->pytorch_utils) (20.4)\n",
            "Collecting GitPython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/bc/ae32e07e89cc25b9e5c793d19a1e5454d30a8e37d95040991160f942519e/GitPython-3.1.8-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->pytorch_utils) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->pytorch_utils) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->pytorch_utils) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->pytorch_utils) (0.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle<2.0,>=1.2->sacred->pytorch_utils) (1.7.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=18.0->sacred->pytorch_utils) (2.4.7)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle<2.0,>=1.2->sacred->pytorch_utils) (3.1.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pytorch-utils, sacred, py-cpuinfo\n",
            "  Building wheel for pytorch-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-utils: filename=pytorch_utils-0.5.5-cp36-none-any.whl size=14295 sha256=5317445762372cf7759f2946876398642be1c7ff70a1a1b346ae9c8fa8107b2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/c6/30/225a60724bc88f83086829b6047b7b850ff16a8662a7ed280a\n",
            "  Building wheel for sacred (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacred: filename=sacred-0.8.1-py2.py3-none-any.whl size=105018 sha256=60f47b1478e6bd69ad3434b0b9db2720304180f42318f760ac7fe07f546b8027\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/a8/f6/1d5f073245cb0a221962713adf81e56c1c9608083f85ecac9b\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-cp36-none-any.whl size=20071 sha256=c432ebf5e6cc3827e0d5a69e8755dd8f824583f00699155be87974a666638fcf\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/93/7b/127daf0c3a5a49feb2fecd468d508067c733fba5192f726ad1\n",
            "Successfully built pytorch-utils sacred py-cpuinfo\n",
            "Installing collected packages: jsonpickle, munch, py-cpuinfo, colorama, smmap, gitdb, GitPython, sacred, pytorch-utils\n",
            "Successfully installed GitPython-3.1.8 colorama-0.4.3 gitdb-4.0.5 jsonpickle-1.4.1 munch-2.5.0 py-cpuinfo-7.0.0 pytorch-utils-0.5.5 sacred-0.8.1 smmap-3.0.4\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Collecting adversarial-robustness-toolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/36/0db6c6518d8e4ae6c3c84574966dd6a7f37016a0003a7658ac77658aa2cb/adversarial_robustness_toolbox-1.4.0-py3-none-any.whl (760kB)\n",
            "\u001b[K     |████████████████████████████████| 768kB 6.0MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (0.10.2)\n",
            "Collecting mypy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/9d/914bb0c71292ffd7e1c9728b9366f9ea34c874f5ca12ac6005a400e4d130/mypy-0.782-cp36-cp36m-manylinux1_x86_64.whl (20.8MB)\n",
            "\u001b[K     |████████████████████████████████| 20.8MB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.5)\n",
            "Collecting scikit-learn==0.22.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/7f/366dcba1ba076a88a50bea732dbc033c0c5bbf7876010e6edc67948579d5/scikit_learn-0.22.2-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (4.41.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.2)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Collecting cma\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/c0/0a1c41f7cad0a51e07991cf86423d0e6651d035f1fe7dcff48e8858848f2/cma-3.0.3-py2.py3-none-any.whl (230kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (50.3.0)\n",
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python->adversarial-robustness-toolbox) (0.16.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->adversarial-robustness-toolbox) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from statsmodels->adversarial-robustness-toolbox) (1.0.5)\n",
            "Collecting typed-ast<1.5.0,>=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/ed/5459080d95eb87a02fe860d447197be63b6e2b5e9ff73c2b0a85622994f4/typed_ast-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (737kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 30.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from mypy->adversarial-robustness-toolbox) (3.7.4.3)\n",
            "Collecting mypy-extensions<0.5.0,>=0.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/eb/975c7c080f3223a5cdaff09612f3a5221e4ba534f7039db34c35d95fa6a5/mypy_extensions-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy->adversarial-robustness-toolbox) (0.48.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.2->adversarial-robustness-toolbox) (0.16.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->statsmodels->adversarial-robustness-toolbox) (2018.9)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy->adversarial-robustness-toolbox) (0.31.0)\n",
            "Installing collected packages: ffmpeg-python, typed-ast, mypy-extensions, mypy, scikit-learn, cma, pydub, adversarial-robustness-toolbox\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed adversarial-robustness-toolbox-1.4.0 cma-3.0.3 ffmpeg-python-0.2.0 mypy-0.782 mypy-extensions-0.4.3 pydub-0.24.1 scikit-learn-0.22.2 typed-ast-1.4.1\n",
            "Collecting kornia\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/18/f767c3f8c28945f0ae5d5db34517f56897cece8175389f54cb8ffacdab99/kornia-0.4.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<1.7.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from kornia) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from kornia) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.7.0,>=1.6.0->kornia) (0.16.0)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhEI1Frmdqam"
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from art.utils import load_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LBn482vwhAc"
      },
      "source": [
        "if adjoint:\n",
        "    from torchdiffeq import odeint_adjoint as odeint\n",
        "else:\n",
        "    from torchdiffeq import odeint\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "def norm(dim):\n",
        "    return nn.GroupNorm(min(32, dim), dim)\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
        "        return x.view(-1, shape)\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.norm1 = norm(inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.norm2 = norm(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "\n",
        "        out = self.relu(self.norm1(x))\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            shortcut = self.downsample(out)\n",
        "\n",
        "        out = self.conv1(out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        return out + shortcut\n",
        "\n",
        "class ConcatConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_in, dim_out, ksize=3, stride=1, padding=0, dilation=1, groups=1, bias=True, transpose=False):\n",
        "        super(ConcatConv2d, self).__init__()\n",
        "        module = nn.ConvTranspose2d if transpose else nn.Conv2d\n",
        "        self._layer = module(\n",
        "            dim_in + 1, dim_out, kernel_size=ksize, stride=stride, padding=padding, dilation=dilation, groups=groups,\n",
        "            bias=bias\n",
        "        )\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        tt = torch.ones_like(x[:, :1, :, :]) * t\n",
        "        ttx = torch.cat([tt, x], 1)\n",
        "        return self._layer(ttx)\n",
        "\n",
        "class ODEfunc(nn.Module):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(ODEfunc, self).__init__()\n",
        "        self.norm1 = norm(dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
        "        self.norm2 = norm(dim)\n",
        "        self.conv2 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
        "        self.norm3 = norm(dim)\n",
        "        self.nfe = 0\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        self.nfe += 1\n",
        "        out = self.norm1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(t, out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(t, out)\n",
        "        out = self.norm3(out)\n",
        "        return out\n",
        "\n",
        "class ODEBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, odefunc):\n",
        "        super(ODEBlock, self).__init__()\n",
        "        self.odefunc = odefunc\n",
        "        self.integration_time = torch.tensor([0, 1]).float()\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.integration_time = self.integration_time.type_as(x)\n",
        "        out = odeint(self.odefunc, x, self.integration_time, rtol=tol, atol=tol)\n",
        "        return out[1]\n",
        "\n",
        "    @property\n",
        "    def nfe(self):\n",
        "        return self.odefunc.nfe\n",
        "\n",
        "    @nfe.setter\n",
        "    def nfe(self, value):\n",
        "        self.odefunc.nfe = value\n",
        "\n",
        "\n",
        "device = torch.device('cuda:' + str(gpu) if torch.cuda.is_available() else 'cpu')\n",
        "is_odenet = network == 'odenet'\n",
        "\n",
        "if downsampling_method == 'conv':\n",
        "        downsampling_layers = [\n",
        "            nn.Conv2d(1, 64, 3, 1),\n",
        "            norm(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 4, 2, 1),\n",
        "            norm(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 4, 2, 1),\n",
        "        ]\n",
        "elif downsampling_method == 'res':\n",
        "        downsampling_layers = [\n",
        "            nn.Conv2d(1, 64, 3, 1),\n",
        "            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n",
        "            ResBlock(64, 64, stride=2, downsample=conv1x1(64, 64, 2)),\n",
        "        ]\n",
        "\n",
        "feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]\n",
        "fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGqkHtRWSGqT"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "network = 'odenet' # 'resnet'\n",
        "tol = 1e-3\n",
        "adjoint = False # True\n",
        "downsampling_method = 'conv' # 'res'\n",
        "nepochs = 2\n",
        "data_aug = True # False\n",
        "lr = 0.1\n",
        "batch_size = 128\n",
        "test_batch_size = 1000\n",
        "save = './experiment1'\n",
        "debug = 'store_true'\n",
        "gpu = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_I4zfhMeAhg",
        "outputId": "be1a1b5f-83d5-4f2c-bb0a-40046eabe697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Step 1: Load the MNIST dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
        "print('Step 1: Load the MNIST dataset')\n",
        "# Step 1a: Swap axes to PyTorch's NCHW format\n",
        "\n",
        "x_train = np.swapaxes(x_train, 1, 3).astype(np.float32)\n",
        "x_test = np.swapaxes(x_test, 1, 3).astype(np.float32)\n",
        "print(\"Step 1a: Swap axes to PyTorch's NCHW format\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1: Load the MNIST dataset\n",
            "Step 1a: Swap axes to PyTorch's NCHW format\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hISB-uAeEfx",
        "outputId": "6ea251fb-0dee-4d62-d0d5-51f5e3bbaaea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "model_sequenced = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)\n",
        "model_shuffled = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)\n",
        "\n",
        "# Step 2a: Define the loss function and the optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_sequenced = optim.SGD(model_sequenced.parameters(), lr=0.01)\n",
        "optimizer_shuffled = optim.SGD(model_shuffled.parameters(), lr=0.01)\n",
        "print('Step 2a: Define the loss function and the optimizer')\n",
        "# Step 3: Create the ART classifier\n",
        "\n",
        "\n",
        "\n",
        "classifier_for_shuffled = PyTorchClassifier(\n",
        "    model=model_sequenced,\n",
        "    clip_values=(min_pixel_value, max_pixel_value),\n",
        "    loss=criterion,\n",
        "    optimizer=optimizer_shuffled,\n",
        "    input_shape=(1, 28, 28),\n",
        "    nb_classes=10,\n",
        ")\n",
        "classifier_for_sequenced = PyTorchClassifier(\n",
        "    model=model_shuffled,\n",
        "    clip_values=(min_pixel_value, max_pixel_value),\n",
        "    loss=criterion,\n",
        "    optimizer=optimizer_sequenced,\n",
        "    input_shape=(1, 28, 28),\n",
        "    nb_classes=10,\n",
        ")\n",
        "print('Step 3: Create the ART classifier')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 2a: Define the loss function and the optimizer\n",
            "Step 3: Create the ART classifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry5MPe6-ePtq",
        "outputId": "eb1ba4f6-e25b-4010-9bd0-afda7ea72831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Step 6: Generate adversarial test examples\n",
        "attack_sequenced = FastGradientMethod(estimator=classifier_for_sequenced, eps=0.2)\n",
        "attack_shuffled = FastGradientMethod(estimator=classifier_for_shuffled, eps=0.2)\n",
        "x_test_adv_sequenced = attack_sequenced.generate(x=x_test)\n",
        "x_test_adv_shuffled = attack_shuffled.generate(x=x_test)\n",
        "x_train_adv_sequenced = attack_sequenced.generate(x=x_train)\n",
        "x_train_adv_shuffled = attack_shuffled.generate(x=x_train)\n",
        "print('Step 6: Generate adversarial test examples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 6: Generate adversarial test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3At5ZpDKgHhw",
        "outputId": "408f6f7f-a6a7-4944-f6d3-a7f9d7359c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "sequenced_train_set, sequenced_label_set = np.concatenate((x_train, x_train_adv_sequenced), axis=0), np.concatenate((y_train, y_train), axis=0)\n",
        "shuffled_train_set, shuffled_label_set = shuffle(np.concatenate((x_train, x_train_adv_shuffled), axis=0), np.concatenate((y_train, y_train), axis=0), random_state=0)\n",
        "print(sequenced_train_set.shape, sequenced_label_set.shape)\n",
        "print(shuffled_train_set.shape, shuffled_label_set.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120000, 1, 28, 28) (120000, 10)\n",
            "(120000, 1, 28, 28) (120000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrKn5mkUdBT1",
        "outputId": "07564271-4c3a-4c71-e1c1-1edd24f5300a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "classifier_for_sequenced.fit(sequenced_train_set, sequenced_label_set, batch_size=64, nb_epochs=nepochs)\n",
        "print('Trained on an sequenced adv trainset')\n",
        "classifier_for_shuffled.fit(shuffled_train_set, shuffled_label_set, batch_size=64, nb_epochs=nepochs)\n",
        "print('Trained on an shuffled adv trainset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trained on an sequenced adv trainset\n",
            "Trained on an shuffled adv trainset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL4Y6TAXhmsd",
        "outputId": "f5c45ba1-7ce9-4be3-c001-18545749866e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "predictions_sequenced = classifier_for_sequenced.predict(x_test_adv_sequenced)\n",
        "predictions_shuffled = classifier_for_shuffled.predict(x_test_adv_shuffled)\n",
        "accuracy_sequenced = np.sum(np.argmax(predictions_sequenced, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "accuracy_shuffled = np.sum(np.argmax(predictions_shuffled, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on adv sequenced test examples: {}%\".format(accuracy_sequenced * 100))\n",
        "print(\"Accuracy on adv shuffled test examples: {}%\".format(accuracy_shuffled * 100))\n",
        "print('Step 7: Evaluate the ART classifier on adversarial test examples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on adv sequenced test examples: 98.92999999999999%\n",
            "Accuracy on adv shuffled test examples: 98.92999999999999%\n",
            "Step 7: Evaluate the ART classifier on adversarial test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUTGfQKBoN5G"
      },
      "source": [
        "model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "classifier = PyTorchClassifier(\n",
        "    model=model,\n",
        "    clip_values=(min_pixel_value, max_pixel_value),\n",
        "    loss=criterion,\n",
        "    optimizer=optimizer,\n",
        "    input_shape=(1, 28, 28),\n",
        "    nb_classes=10,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i2z8X2TU6Im"
      },
      "source": [
        "classifier.fit(x_train, y_train, batch_size=64, nb_epochs=nepochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqqhtyy-amf2"
      },
      "source": [
        "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
        "x_test_adv = attack.generate(x=x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceSy6xV8cC8y",
        "outputId": "646f07f8-9f42-44a4-e00e-fabda53934d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WZYHgJocGK_",
        "outputId": "5bd5b0c7-b1b0-45f5-b988-83e73527dece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "3+5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymjdD-B6d9Zc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}